# Lexical Analysis

+ **Alphabet** - A _finite_ collection of symbols called **Tokens** denoted
  with $\Sigma$.
+ **Token** - An individual symbol. A unit of source code that consists of a
  **Lexeme** and a **Token Type**.
+ **Token Type** - A category of **Tokens**.
+ **Strings** - Sequences of symbols from the alphabet $\Sigma$.
  - We concern ourselves with _finite_ strings.
  - The set of all finite strings is denoted by $\Sigma^*$
  - A snippet of code is considered a string over some alphabet of lexemes.
+ **Lexeme** - The graphical/visual representation of a **Token**. A substring
  in the source code.
+ **Language** - A subset of strings in $\Sigma^*$:
  $$ L \sube \Sigma^* $$
+ If some string $s \in L$, we say that $s$ is valid with respect to the
  language $L$.
+ Strings can have different encodings but still represent the same thing.
  - e.g. ASCII chars, binary, token set, etc. encodings.
+ Conversion between different alphabets is possible.

## Tokenization

+ Taking the encoded string of a language and converting it to a sequence of
  tokens.
+ Tokens can belong to _categories_ also called _token types_.
+ These token types can be defined to best describe strings of a language.

The goal is to convert the source code of a language ($\Sigma^*_{\text{chars}}$) into 
a token stream ($\Sigma^*_{\textit{lang}}$). The exact set of tokens used is specific
to the language.

For example, Java source written with ASCII chars gets tokenized into a stream
of tokens:
```java
  // Some tokens in this example are: 'class', '{', '}'
  // We could define an ID token type that represent all possible Java
  // identifiers.
  class MyClass {
    int myId;
  }
```
+ We encode $\Sigma_{\textit{lang}}$ as a pair of Token Type and Lexeme to
  ensure we can reconstruct the original string.
+ If we denote all possible tokens as $\textbf{Tok}$, the lexical analyzer, or
  lexer, is a function:
  $$ \text{lex} : \Sigma^*_{\text{chars}} \rarr \textbf{Tok}^* $$

## General Design of a Lexical Analyzer

+ Token types can be defined with reqular expresion syntax.
+ Strings are scanned left to right.
  - Track the current position.
  - Try to match patterns at the current position. Multiple may apply.
  - Decide on how to solve ambiguity:
    * e.g. Longest match wins.
    * First rule defined wins.

---

# Advanced Lexical Analyzer
# Structured Lexer Generation

+ declarative rules. preferably in its own files.
+ groups of rules.

Toolchain: ANTLR
+ generates java source that implements a lexer from a grammar file.

How to use the generated SimpleLexer.class?
+ Obtain a CharStream(s): org.antlr.v4.runtime
+ Obtain a SimpleLexer(charstream): implementation generated by antlr.
+ Obtain a commonTokenStream from the lexer.

---
+ powerset construction gets rid of epsilons when applied to NFA.
+ regular: can construct discrete automata to describe source code.
+ prog-langs != regular

Non-Regular Language
+ L = all matching brackets.
+ e.g. "()", "(())", ..., but not "(()" or similar
Attempt:
```
L_n = open close , <= n bracket pairs
Goal:
+ lim_n->inf(L_n)
+ Not finite!
  start -> ( -> ( ...n-times (
      |    |    |            |
      + <- ) <- ) ...n-times )
RE < Context Free Grammar < Context Sensitive Grammar < ???
```

---

left-factored implies only one alternation is left recursive.
+ Otherwise, it wouldn't be left-factored.

---

Exam Stuff:

20/70 %
+ Automatons:
  - Define a language with NFA's.
  - Translate an NFA to a DFA using powerset construction.
    * Given transition diagram, does it describe the same language as the NFA?
    * Convert it to a DFA.
  - Translate a Regex to an NFA via the thompson constructions.
+ Automatons Application in lexical analysis:
  - Substrings of source code as Tokens.
  - Token types, patterns, lexemes.
  - ANTLR lexer generator (probably not).
50/70 %
+ Context Free Grammars
  - Define languages with CFGs and Regexs
    * Can a language be defined with regexes? Does it need CFGs instead.
  - Parse tree of sentences.
  - Derivations.
  - Fix known ambiguities.
  - Left factoring.
  - Left recursion.

Multiple choice covers all topics.
One aid-sheet allowed.

